# Introduction 

Mathematical physics has a predisposition for High Performance Computing (HPC). Consider, for example, the equations describing fluid flow. The combined output of an engineer and mathematical physicist, the Navier-Stokes Equations were established by 1850 – after almost three decade’s worth of combined effort. Because this set of coupled partial differential equations establishes the underpinnings for weather prediction, for example, there has been vested interest in them ever since. Except in the simplest of cases, however, solving the equations that model and simulate weather proves to be mathematically intractable; in other words, for only the simplest of cases could the methods of mathematics be applied to solve the set of equations required to predict weather. (Stated in mathematical terms, only in restricted scenarios can purely mathematical methods produce closed-form solutions.) As early as the 1920s then, interest in numerically solving this involved set of equations was growing. In fact, prior to the introduction of devices that could actually perform computations, people were employed in the manual process as ‘human computers.’ It’s not surprising then that Numerical Weather Prediction (NWP) and computers have enjoyed an intertwined history spanning some seven decades and counting. With every advance in computing since the ENIAC in the early 1950s, atmospheric scientists were able to tackle increasingly challenging and realistic use cases. Today, this legacy is routinely leveraged to allow for weather forecasts (including predictions of severe weather), climate-scenario projections, and more. 

The Navier-Stokes Equations represent just one of a class of Grand Challenge Equations in mathematical physics. Representing a broad array of science and engineering disciplines, these equations share characteristics common to those in the Navier-Stokes Equations: problems of interest can be expressed mathematically, but require the application of numerical methods for approximate solutions to be obtained (see schematic below). Moreover, and particularly relevant here, is that these Grand Challenge Equations are exceedingly highly demanding of HPC. In fact, it’s fair to state that such equations have provided ample motivation for advancing HPC. Mathematical physics, it seems, has a predisposition for driving HPC.

For many years it's been routine for NWP models and simulations to assimilate large volumes of observational data in near real time. By periodically ‘truthing’ NWP output with actual data (temperature, pressure, relative humidity, wind speed and direction, plus density), active feedback decreases the uncertainty inherent in the results obtained (see schematic below). So powerful is this data-assimilation paradigm that forecasting centers have _reanalyzed_ historical weather events to reduce the uncertainty inherent in ‘postdicted’ results. In other words, because data regarding what actually happened is available, forecasting centers have the ‘ultimate truth’ available to refine their models and simulations. Thus, modern incarnations of the Grand Challenge Equations are computationally as well as data intensive. Of course, the original set of classic Grand Challenge Equations has been complemented multiple times over. Today, the breadth and depth of interests extend well beyond those of purely mathematical physics. Again, the specifics may differ, but the upshot remains the same: the equations of science and engineering have a predisposition for driving HPC.

This framing of HPC has been drawn from the blog post [here](https://terawe.com/HpcAI). The post expounds upon the challenges that HPC poses for IT infrastructure. As Deep Learning continues to advance, analogous infrastructural challenges are rapidly emerging. 